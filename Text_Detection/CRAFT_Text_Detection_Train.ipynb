{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CRAFT_Text_Detection_Train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuJPeClobSt7"
      },
      "source": [
        "# !gdown --id 1eAymcrGvjlnGt3amBxXPvmKJODtE34ZD"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-R9dHtzbShS"
      },
      "source": [
        "# !unzip data.zip"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yrfVDLOpAl5"
      },
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwBoUruXpDmF"
      },
      "source": [
        "import time\n",
        "import os\n",
        "import torch\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import torch.utils.data as data\n",
        "import random\n",
        "import cv2\n",
        "import copy\n",
        "from collections import namedtuple\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "from torchvision import models\n",
        "from torchvision.models.vgg import model_urls\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FuviLJDpIXE"
      },
      "source": [
        "### Utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pNCE9NFpLuV"
      },
      "source": [
        "if not os.path.isdir('store'):\n",
        "  os.mkdir('store')\n",
        "\n",
        "def gauss_normal_generate(d):\n",
        "    # generate normal gauss map\n",
        "    width = d\n",
        "    height = d\n",
        "    center_x = width / 2\n",
        "    center_y = height / 2\n",
        "    # sigma principle to make the number at the edge of the circle to be very small\n",
        "    sigma = d / 3\n",
        "    Gauss_map = np.zeros((height, width))\n",
        "    for i in range(height):\n",
        "        for j in range(width):\n",
        "            dis = (i - center_y) ** 2 + (j - center_x) ** 2\n",
        "            if dis > (d ** 2) / 4:\n",
        "                value = 0\n",
        "            else:\n",
        "                value = np.exp(-0.5 * dis / sigma ** 2)\n",
        "            Gauss_map[i, j] = value\n",
        "    return Gauss_map\n",
        "\n",
        "\n",
        "def cvt2HeatmapImg(img):\n",
        "    # display\n",
        "    img = (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
        "    img = cv2.applyColorMap(img, cv2.COLORMAP_JET)\n",
        "    return img\n",
        "\n",
        "\n",
        "def cvt2HeatmapMatrix(img):\n",
        "    # calculate\n",
        "    img = (np.clip(img, 0, 1) * 255).astype(np.uint8)\n",
        "    return img\n",
        "\n",
        "\n",
        "def point_generate(x1, y1, x2, y2):\n",
        "    x = []\n",
        "    y = []\n",
        "    mid_x1 = int((x1[0] + x1[2]) / 2)\n",
        "    mid_y1 = int((y1[0] + y1[2]) / 2)\n",
        "    mid_x2 = int((x2[0] + x2[2]) / 2)\n",
        "    mid_y2 = int((y2[0] + y2[2]) / 2)\n",
        "    x.append(copy.deepcopy(int((x1[0] + x1[1] + mid_x1) / 3)))\n",
        "    x.append(copy.deepcopy(int((x2[0] + x2[1] + mid_x2) / 3)))\n",
        "    x.append(copy.deepcopy(int((x2[2] + x2[3] + mid_x2) / 3)))\n",
        "    x.append(copy.deepcopy(int((x1[2] + x1[3] + mid_x1) / 3)))\n",
        "    y.append(copy.deepcopy(int((y1[0] + y1[1] + mid_y1) / 3)))\n",
        "    y.append(copy.deepcopy(int((y2[0] + y2[1] + mid_y2) / 3)))\n",
        "    y.append(copy.deepcopy(int((y2[2] + y2[3] + mid_y2) / 3)))\n",
        "    y.append(copy.deepcopy(int((y2[2] + y2[3] + mid_y2) / 3)))\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def interval_list_generate(text):\n",
        "    word_list = []\n",
        "    for part in text:\n",
        "        part_word_list = part.strip().replace(' ', '\\n').split('\\n')\n",
        "        for i in range(len(part_word_list) - 1, -1, -1):\n",
        "            if part_word_list[i] == '':\n",
        "                part_word_list.remove('')\n",
        "        word_list += part_word_list\n",
        "    interval_i = 0\n",
        "    interval_list = []\n",
        "    for word in word_list:\n",
        "        interval_i += len(word)\n",
        "        interval_list.append(copy.deepcopy(interval_i))\n",
        "    interval_list = interval_list[:-1]\n",
        "    return interval_list\n",
        "\n",
        "\n",
        "class averager(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def add(self, v):\n",
        "        count = v.numel()\n",
        "        v = v.sum()\n",
        "        self.n_count += count\n",
        "        self.sum += v\n",
        "\n",
        "    def reset(self):\n",
        "        self.n_count = 0\n",
        "        self.sum = 0\n",
        "\n",
        "    def val(self):\n",
        "        res = 0\n",
        "        if self.n_count != 0:\n",
        "            res = self.sum / float(self.n_count)\n",
        "        return res\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9N6we-SpTck"
      },
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9yobE7GpVYF"
      },
      "source": [
        "class SynthText(object):\n",
        "    def __init__(self):\n",
        "        self.generate_information()\n",
        "\n",
        "    def generate_information(self):\n",
        "        self.data = sio.loadmat('./data/SynthText/gt.mat')\n",
        "        char_BB = self.data['charBB']\n",
        "        self.cor_list = char_BB[0]\n",
        "        img_txt = self.data['txt']\n",
        "        self.text = img_txt[0]\n",
        "        names = self.data['imnames']\n",
        "        # the third 0 to get the string in list\n",
        "        self.name = names[0]\n",
        "        self.gauss_map = gauss_normal_generate(20)\n",
        "\n",
        "    def len(self):\n",
        "        return len(self.data['charBB'][0])\n",
        "\n",
        "    def im_read_resize(self, path):\n",
        "        img = cv2.imread(path)\n",
        "        img_size = (img.shape[0], img.shape[1])\n",
        "        if img_size[0] > img_size[1]:\n",
        "            img = np.rot90(img, -1)\n",
        "        resized_img = cv2.resize(img, (600, 400), cv2.INTER_NEAREST)\n",
        "        return resized_img, img_size\n",
        "\n",
        "    def char_label_generate(self, gauss_map, img_size, cor_list):\n",
        "        # generate the first map with all char box being replaced with gauss map\n",
        "        h = img_size[0]\n",
        "        w = img_size[1]\n",
        "        char_label = np.zeros((h, w))\n",
        "        char_number = cor_list.shape[2]\n",
        "        for i in range(char_number):\n",
        "            x = []\n",
        "            y = []\n",
        "            for index in range(4):\n",
        "                x.append(copy.deepcopy(int(cor_list[0][index][i])))\n",
        "                y.append(copy.deepcopy(int(cor_list[1][index][i])))\n",
        "            x_min = max(min(x), 0)\n",
        "            x_max = min(max(x), w)\n",
        "            y_min = max(min(y), 0)\n",
        "            y_max = min(max(y), h)\n",
        "            point1 = np.array([[0, 0], [19, 0], [19, 19], [0, 19]], dtype='float32')\n",
        "            point2 = np.array([[x[0] - x_min, y[0] - y_min], [x[1] - x_min, y[1] - y_min],\n",
        "                               [x[2] - x_min, y[2] - y_min], [x[3] - x_min, y[3] - y_min]], dtype='float32')\n",
        "            w_final = x_max - x_min\n",
        "            h_final = y_max - y_min\n",
        "            m = cv2.getPerspectiveTransform(point1, point2)\n",
        "            target = cv2.warpPerspective(gauss_map, m, (w_final, h_final), cv2.INTER_NEAREST)\n",
        "            for j in range(y_min, y_max):\n",
        "                for k in range(x_min, x_max):\n",
        "                    if target[j - y_min][k - x_min] > char_label[j][k]:\n",
        "                        char_label[j, k] = target[j - y_min][k - x_min]\n",
        "        if h > w:\n",
        "            char_label = np.rot90(char_label, -1)\n",
        "        char_label = cv2.resize(char_label, (300, 200), cv2.INTER_NEAREST)\n",
        "        char_label = cvt2HeatmapMatrix(char_label)\n",
        "        return char_label\n",
        "\n",
        "    def interval_label_generate(self, gauss_map, img_size, cor_list, interval_list):\n",
        "        # generate the first map with all char box being replaced with gauss map\n",
        "        h = img_size[0]\n",
        "        w = img_size[1]\n",
        "        interval_label = np.zeros((h, w))\n",
        "        char_number = cor_list.shape[2]\n",
        "        for i in range(char_number - 1):\n",
        "            if i + 1 in interval_list:\n",
        "                continue\n",
        "            x1 = []\n",
        "            y1 = []\n",
        "            x2 = []\n",
        "            y2 = []\n",
        "            for index in range(4):\n",
        "                x1.append(copy.deepcopy(int(cor_list[0][index][i])))\n",
        "                y1.append(copy.deepcopy(int(cor_list[1][index][i])))\n",
        "                x2.append(copy.deepcopy(int(cor_list[0][index][i + 1])))\n",
        "                y2.append(copy.deepcopy(int(cor_list[1][index][i + 1])))\n",
        "            x, y = point_generate(x1, y1, x2, y2)\n",
        "            x_min = max(min(x), 0)\n",
        "            x_max = min(max(x), w)\n",
        "            y_min = max(min(y), 0)\n",
        "            y_max = min(max(y), h)\n",
        "            point1 = np.array([[0, 0], [19, 0], [19, 19], [0, 19]], dtype='float32')\n",
        "            point2 = np.array([[x[0] - x_min, y[0] - y_min], [x[1] - x_min, y[1] - y_min],\n",
        "                               [x[2] - x_min, y[2] - y_min], [x[3] - x_min, y[3] - y_min]], dtype='float32')\n",
        "            w_final = x_max - x_min\n",
        "            h_final = y_max - y_min\n",
        "            m = cv2.getPerspectiveTransform(point1, point2)\n",
        "            target = cv2.warpPerspective(gauss_map, m, (w_final, h_final), cv2.INTER_NEAREST)\n",
        "            for j in range(y_min, y_max):\n",
        "                for k in range(x_min, x_max):\n",
        "                    if target[j - y_min][k - x_min] > interval_label[j][k]:\n",
        "                        interval_label[j, k] = target[j - y_min][k - x_min]\n",
        "        if h > w:\n",
        "            interval_label = np.rot90(interval_label, -1)\n",
        "        interval_label = cv2.resize(interval_label, (300, 200), cv2.INTER_NEAREST)\n",
        "        interval_label = cvt2HeatmapMatrix(interval_label)\n",
        "        return interval_label"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OdrypnSp3Jw"
      },
      "source": [
        "### Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtR1oyCip7g1"
      },
      "source": [
        "class ImageLoader_synthtext(data.Dataset):\n",
        "    def __init__(self):\n",
        "        self.dataset = SynthText()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.dataset.len()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img_path = './data/SynthText/' + self.dataset.name[index].replace(\" \", \"\")\n",
        "        img, img_size = self.dataset.im_read_resize(img_path)\n",
        "        char_label = self.dataset.char_label_generate(self.dataset.gauss_map, img_size, self.dataset.cor_list[index])\n",
        "        interval_list = interval_list_generate(self.dataset.text[index])\n",
        "        interval_label = self.dataset.interval_label_generate(self.dataset.gauss_map, img_size,\n",
        "                                                              self.dataset.cor_list[index], interval_list)\n",
        "        img, char_label, interval_label = random_augmentation(img, char_label, interval_label)\n",
        "        img = torch.Tensor(img)\n",
        "        char_label = torch.Tensor(char_label)\n",
        "        interval_label = torch.Tensor(interval_label)\n",
        "        return img, char_label, interval_label"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jbmKw9oqCB1"
      },
      "source": [
        "def collate(batch):\n",
        "    imgs = []\n",
        "    char_labels = []\n",
        "    interval_labels = []\n",
        "    for sample in batch:\n",
        "        imgs.append(sample[0])\n",
        "        char_labels.append(sample[1])\n",
        "        interval_labels.append(sample[2])\n",
        "    imgs_stack = torch.stack(imgs, 0)\n",
        "    char_labels_stack = torch.stack(char_labels, 0)\n",
        "    interval_labels_stack = torch.stack(interval_labels, 0)\n",
        "    return imgs_stack.permute(0, 3, 1, 2), char_labels_stack, interval_labels_stack\n",
        "\n",
        "\n",
        "def random_augmentation(image, char_label, interval_label):\n",
        "    f = ImageTransfer(image, char_label, interval_label)\n",
        "    seed = random.randint(0, 5)  # 0: original image used\n",
        "    if 0 < seed < 5:\n",
        "        methods = ['rotate', 'add_noise', 'change_contrast', 'change_hsv']\n",
        "        image, char_label, interval_label = getattr(f, methods[seed - 1])()\n",
        "    return image, char_label, interval_label\n",
        "\n",
        "\n",
        "class ImageTransfer(object):\n",
        "    \"\"\"add noise, rotate, change contrast, change_hsv\"\"\"\n",
        "\n",
        "    def __init__(self, image, char_label, interval_label):\n",
        "        \"\"\"image: a ndarray with size [h, w, 3]\"\"\"\n",
        "        \"\"\"label: a ndarray with size [h/2, w/2]\"\"\"\n",
        "        self.image = image\n",
        "        self.char_label = char_label\n",
        "        self.interval_label = interval_label\n",
        "\n",
        "    def add_noise(self):\n",
        "        img = self.image * (np.random.rand(*self.image.shape) * 0.4 + 0.6)\n",
        "        img = img.astype(np.uint8)\n",
        "        char_label = self.char_label\n",
        "        interval_label = self.interval_label\n",
        "        return img, char_label, interval_label\n",
        "\n",
        "    def rotate(self, angle=None, center=None, scale=1.0, angle_min=20, angle_max=180):\n",
        "        h, w = self.image.shape[:2]\n",
        "        h1, w1 = self.char_label.shape\n",
        "        if angle is None:\n",
        "            angle = random.randint(angle_min, angle_max) if random.random() < 0.5 else random.randint(-angle_max,\n",
        "                                                                                                      -angle_min)\n",
        "        if center is None:\n",
        "            center = (w // 2, h // 2)\n",
        "            center1 = (w1 // 2, h1 // 2)\n",
        "        M = cv2.getRotationMatrix2D(center, angle, scale)\n",
        "        M1 = cv2.getRotationMatrix2D(center1, angle, scale)\n",
        "        return cv2.warpAffine(self.image, M, (w, h)), cv2.warpAffine(self.char_label, M1, (w1, h1)), cv2.warpAffine(\n",
        "            self.interval_label, M1, (w1, h1))\n",
        "\n",
        "    def change_contrast(self):\n",
        "        if random.random() < 0.5:\n",
        "            k = random.randint(5, 9) / 10.0\n",
        "        else:\n",
        "            k = random.randint(11, 15) / 10.0\n",
        "        b = 128 * (k - 1)\n",
        "        img = self.image.astype(np.float)\n",
        "        img = k * img - b\n",
        "        img = np.maximum(img, 0)\n",
        "        img = np.minimum(img, 255)\n",
        "        img = img.astype(np.uint8)\n",
        "        char_label = self.char_label\n",
        "        interval_label = self.interval_label\n",
        "        return img, char_label, interval_label\n",
        "\n",
        "    def change_hsv(self):\n",
        "        img = cv2.cvtColor(self.image, cv2.COLOR_BGR2HSV)\n",
        "        char_label = self.char_label\n",
        "        interval_label = self.interval_label\n",
        "        s = random.random()\n",
        "\n",
        "        def ch_h():\n",
        "            dh = random.randint(2, 10) * random.randrange(-1, 2, 2)\n",
        "            img[:, :, 0] = (img[:, :, 0] + dh) % 180\n",
        "\n",
        "        def ch_s():\n",
        "            ds = random.random() * 0.25 + 0.7\n",
        "            img[:, :, 1] = ds * img[:, :, 1]\n",
        "\n",
        "        def ch_v():\n",
        "            dv = random.random() * 0.35 + 0.6\n",
        "            img[:, :, 2] = dv * img[:, :, 2]\n",
        "\n",
        "        if s < 0.25:\n",
        "            ch_h()\n",
        "        elif s < 0.50:\n",
        "            ch_s()\n",
        "        elif s < 0.75:\n",
        "            ch_v()\n",
        "        else:\n",
        "            ch_h()\n",
        "            ch_s()\n",
        "            ch_v()\n",
        "        return cv2.cvtColor(img, cv2.COLOR_HSV2BGR), char_label, interval_label"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCJRpPSzqC5P"
      },
      "source": [
        "dataset = ImageLoader_synthtext()\n",
        "\n",
        "data_loader = data.DataLoader(dataset, 4, num_workers=1, shuffle=True, collate_fn=collate)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvnPjklpqTdj"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKjNzV9PqVRD"
      },
      "source": [
        "def init_weights(modules):\n",
        "    for m in modules:\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            init.xavier_uniform_(m.weight.data)\n",
        "            if m.bias is not None:\n",
        "                m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            m.weight.data.fill_(1)\n",
        "            m.bias.data.zero_()\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            m.weight.data.normal_(0, 0.01)\n",
        "            m.bias.data.zero_()\n",
        "\n",
        "\n",
        "class vgg16_bn(torch.nn.Module):\n",
        "    def __init__(self, pretrained=True, freeze=True):\n",
        "        super(vgg16_bn, self).__init__()\n",
        "        model_urls['vgg16_bn'] = model_urls['vgg16_bn'].replace('https://', 'http://')\n",
        "        # model_urls['vgg16_bn'] = 'vgg16_bn-6c64b313.pth'\n",
        "        vgg_pretrained_features = models.vgg16_bn(pretrained=pretrained).features\n",
        "        self.slice1 = torch.nn.Sequential()\n",
        "        self.slice2 = torch.nn.Sequential()\n",
        "        self.slice3 = torch.nn.Sequential()\n",
        "        self.slice4 = torch.nn.Sequential()\n",
        "        self.slice5 = torch.nn.Sequential()\n",
        "        for x in range(12):  # conv2_2\n",
        "            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n",
        "        for x in range(12, 19):  # conv3_3\n",
        "            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n",
        "        for x in range(19, 29):  # conv4_3\n",
        "            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n",
        "        for x in range(29, 39):  # conv5_3\n",
        "            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n",
        "\n",
        "        # fc6, fc7 without atrous conv\n",
        "        self.slice5 = torch.nn.Sequential(\n",
        "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
        "            nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6),\n",
        "            nn.Conv2d(1024, 1024, kernel_size=1)\n",
        "        )\n",
        "\n",
        "        if not pretrained:\n",
        "            init_weights(self.slice1.modules())\n",
        "            init_weights(self.slice2.modules())\n",
        "            init_weights(self.slice3.modules())\n",
        "            init_weights(self.slice4.modules())\n",
        "\n",
        "        init_weights(self.slice5.modules())  # no pretrained model for fc6 and fc7\n",
        "\n",
        "        if freeze:\n",
        "            for param in self.slice1.parameters():  # only first conv\n",
        "                param.requires_grad = False\n",
        "\n",
        "    def forward(self, X):\n",
        "        h = self.slice1(X)\n",
        "        h_relu2_2 = h\n",
        "        h = self.slice2(h)\n",
        "        h_relu3_2 = h\n",
        "        h = self.slice3(h)\n",
        "        h_relu4_3 = h\n",
        "        h = self.slice4(h)\n",
        "        h_relu5_3 = h\n",
        "        h = self.slice5(h)\n",
        "        h_fc7 = h\n",
        "        vgg_outputs = namedtuple(\"VggOutputs\", ['fc7', 'relu5_3', 'relu4_3', 'relu3_2', 'relu2_2'])\n",
        "        out = vgg_outputs(h_fc7, h_relu5_3, h_relu4_3, h_relu3_2, h_relu2_2)\n",
        "        return out\n",
        "\n",
        "\n",
        "class double_conv(nn.Module):\n",
        "    def __init__(self, in_ch, mid_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch + mid_ch, mid_ch, kernel_size=1),\n",
        "            nn.BatchNorm2d(mid_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_ch, out_ch, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class CRAFT(nn.Module):\n",
        "    def __init__(self, pretrained=False, freeze=False):\n",
        "        super(CRAFT, self).__init__()\n",
        "\n",
        "        \"\"\" Base network \"\"\"\n",
        "        self.basenet = vgg16_bn(pretrained, freeze)\n",
        "\n",
        "        \"\"\" U network \"\"\"\n",
        "        self.upconv1 = double_conv(1024, 512, 256)\n",
        "        self.upconv2 = double_conv(512, 256, 128)\n",
        "        self.upconv3 = double_conv(256, 128, 64)\n",
        "        self.upconv4 = double_conv(128, 64, 32)\n",
        "\n",
        "        num_class = 2\n",
        "        self.conv_cls = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 16, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, 16, kernel_size=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(16, num_class, kernel_size=1),\n",
        "        )\n",
        "\n",
        "        init_weights(self.upconv1.modules())\n",
        "        init_weights(self.upconv2.modules())\n",
        "        init_weights(self.upconv3.modules())\n",
        "        init_weights(self.upconv4.modules())\n",
        "        init_weights(self.conv_cls.modules())\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" Base network \"\"\"\n",
        "        sources = self.basenet(x)\n",
        "\n",
        "        \"\"\" U network \"\"\"\n",
        "        y = torch.cat([sources[0], sources[1]], dim=1)\n",
        "        y = self.upconv1(y)\n",
        "\n",
        "        y = F.interpolate(y, size=sources[2].size()[2:], mode='bilinear', align_corners=False)\n",
        "        y = torch.cat([y, sources[2]], dim=1)\n",
        "        y = self.upconv2(y)\n",
        "\n",
        "        y = F.interpolate(y, size=sources[3].size()[2:], mode='bilinear', align_corners=False)\n",
        "        y = torch.cat([y, sources[3]], dim=1)\n",
        "        y = self.upconv3(y)\n",
        "\n",
        "        y = F.interpolate(y, size=sources[4].size()[2:], mode='bilinear', align_corners=False)\n",
        "        y = torch.cat([y, sources[4]], dim=1)\n",
        "        feature = self.upconv4(y)\n",
        "\n",
        "        y = self.conv_cls(feature)\n",
        "\n",
        "        return y.permute(0, 2, 3, 1), feature\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqvtcfadqWow"
      },
      "source": [
        "### Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2yNOVlJqYrF",
        "outputId": "02dadb4d-547a-4219-adf2-b7a1b2697333",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "criterion = torch.nn.MSELoss(reduction='mean')\n",
        "criterion = criterion.to(device)\n",
        "craft = CRAFT(pretrained=True)\n",
        "craft = craft.to(device)\n",
        "\n",
        "optimizer = optim.Adam(craft.parameters(), lr=0.001)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCTwa0gTqlFC"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQAdCwsFqC-P",
        "outputId": "90f688d2-8cdc-4a91-8ffc-cda7a007cc93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "def train_batch(data):\n",
        "    div = 10\n",
        "    craft.train()\n",
        "    img, char_label, interval_label = data\n",
        "    img = img.to(device)\n",
        "    char_label = char_label.to(device)\n",
        "    interval_label = interval_label.to(device)\n",
        "\n",
        "    img.requires_grad_()\n",
        "    optimizer.zero_grad()\n",
        "    preds, _ = craft(img)\n",
        "    cost_char = criterion(preds[:, :, :, 0], char_label).sum() / div\n",
        "    cost_interval = criterion(preds[:, :, :, 1], interval_label).sum() / div\n",
        "    cost = cost_char + cost_interval\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "    return cost\n",
        "\n",
        "\n",
        "loss_avg = averager()\n",
        "\n",
        "for epoch in range(5):\n",
        "    train_iter = iter(data_loader)\n",
        "    i = 0\n",
        "    while i < len(data_loader):\n",
        "        time0 = time.time()\n",
        "        data = train_iter.next()\n",
        "        cost = train_batch(data)\n",
        "        loss_avg.add(cost)\n",
        "        i += 1\n",
        "\n",
        "        # do checkpointing\n",
        "        if i % 100 == 0:\n",
        "            torch.save(craft.state_dict(),\n",
        "                       '{0}/craft_{1}_{2}_{3}.pth'.format('store', epoch, i, loss_avg.val()))\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print('[%d/%d][%d/%d] lr: %.4f Loss: %f Time: %f s' %\n",
        "                  (epoch, 5, i, len(data_loader), optimizer.param_groups[0]['lr'], loss_avg.val(),\n",
        "                   time.time() - time0))\n",
        "            loss_avg.reset()\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0/5][100/1113] lr: 0.0010 Loss: 154.313202 Time: 3.704025 s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-cc9cc897d11f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mtime0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mloss_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-14-cc9cc897d11f>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost_char\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcost_interval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mcost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    117\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                    \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m                    group['eps'])\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYAs3T5HalOf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}